````markdown
# ðŸ§  Retinal Vessel Segmentation with U-Net

This repository contains code and analysis for segmenting blood vessels in retinal images using U-Net, implemented in PyTorch. The project is based on the DRIVE and STARE datasets and explores how skip connections affect model performance in identifying fine vascular structures.

---

## ðŸ“ Project Overview

This project was completed as part of **Assignment 3** for a deep learning course. The task involved implementing, training, and evaluating two U-Net variants:

- **Model 1: U-Net with Skip Connections**  
- **Model 2: U-Net without Skip Connections**

We analyzed how architectural differences influence the segmentation of retinal blood vessels, especially **thin vessels**, which are crucial in early diagnosis of eye diseases.

---

## ðŸ§ª Datasets

- **DRIVE**: Digital Retinal Images for Vessel Extraction  
- **STARE**: Structured Analysis of the Retina  

> Datasets are preloaded on CHPC scratch disks and were used as providedâ€”no modifications or external data used.

---

## ðŸš€ Features

- Full **U-Net architecture** with configurable depth and skip connections
- **Data augmentation**: horizontal and vertical flipping
- **Weighted loss function** to handle class imbalance (background vs. vessels)
- Visual output comparison between predictions and ground truth
- Evaluation using **F1-score**, with a target â‰¥ 0.75 on validation

---

## ðŸ› ï¸ Technologies Used

- Python 3.x
- PyTorch â‰¥ 1.7
- NumPy, scikit-learn, scikit-image
- ImageIO, imagecodecs
- Matplotlib, Seaborn

---

## ðŸ“Š Results

| Model Variant         | Validation F1 Score | Observations                               |
|----------------------|---------------------|--------------------------------------------|
| U-Net (with skips)   | > 0.81              | Performs well on both thick and thin vessels |
| U-Net (no skips)     | < 0.75              | Misses thin vessels due to lack of detail retention |

---

## ðŸ“¸ Sample Outputs

| Ground Truth         | Predicted (U-Net)   |
|----------------------|---------------------|
| ![gt](images/gt1.png)| ![pred](images/pred1.png)|

*(Note: Replace with your actual plots if uploading)*

---

## ðŸ§  Key Insights

- **Skip connections are critical** for preserving spatial resolution in segmentation tasks.
- **Weighted loss functions** significantly improve performance on imbalanced datasets.
- **Simple augmentations** like flipping are highly effective for medical image training.

---

## ðŸ“‚ File Structure

```bash
â”œâ”€â”€ model_ex13.py              # U-Net with skip connections
â”œâ”€â”€ model_ex15.py              # U-Net without skip connections
â”œâ”€â”€ train.py                   # Training loop and evaluation
â”œâ”€â”€ utils.py                   # Data loading, augmentation, etc.
â”œâ”€â”€ Assignment 3 Report.pdf    # Full report with results and analysis
â”œâ”€â”€ README.md                  # This file
````

---

## ðŸ§‘â€ðŸ’» Setup Instructions

1. Create a virtual environment:

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

2. Install required packages:

   ```bash
   pip install -r requirements.txt
   ```

3. (CHPC Users) Load CUDA and modules as per instructions provided in assignment.

4. Run training:

   ```bash
   python train.py
   ```

---

## ðŸ“Œ Acknowledgments

* Based on coursework at the University of Utah.
* Thanks to the creators of the DRIVE and STARE datasets.
* U-Net architecture by Ronneberger et al. (2015).

---

## ðŸ“¬ Contact

For any questions or collaboration ideas, feel free to reach out!

**\[Your Name]**
\Ananya Ananth
\https://www.linkedin.com/in/ananyaananth/

```

---

Would you like me to generate sample `requirements.txt` or code documentation headers too?
```
